\documentclass[a4paper, 12pt, twoside]{article}
\usepackage[utf8]{inputenc}		% LaTeX, comprend les accents !
\usepackage[T1]{fontenc}		
\usepackage[francais]{babel}
\usepackage{lmodern}
\usepackage{ae,aecompl}
\usepackage[top=2.5cm, bottom=2cm,
			left=3cm, right=2.5cm,
			headheight=15pt]{geometry}
\usepackage{graphicx}
\usepackage{eso-pic}	% Nécessaire pour mettre des images en arrière plan
\usepackage{array} 
\usepackage{hyperref}
\input{pagedegarde}


\title{Plateforme de génération d'exercices de programmation corrigés automatiquement par une IA}
\entreprise{Projet académique - Plateforme Ollama}
\datedebut{10 mars 2025}
\datefin{23 mai 2025}
\ecole{Université Paris Nanterre, Département d'Informatique}



\membrea{YAHYA AKIL 44005696}
\membreb{MEHDI BELABBAS 44000690}
\membrec{KARIM ABDALLAH 44020626}


\begin{document}

\pagestyle{empty}
\pagedegarde
\newpage

\tableofcontents
\newpage

\section{Introduction}

Ce rapport présente la conception et le développement d'une plateforme web de génération d'exercices de programmation corrigés automatiquement par une intelligence artificielle. La plateforme vise à aider les débutants en codage en proposant des exercices adaptés aux langages et aux thèmes choisis par l'utilisateur. Elle permet de gagner du temps en générant dynamiquement du contenu pédagogique (énoncés d'exercice, exemples de solution, sorties attendues) sans intervention manuelle. Le point central du projet est l'utilisation d'un modèle de langage avancé, via Ollama, pour créer et corriger les exercices. Nous allons détailler dans ce rapport les fonctionnalités implémentées, l'architecture utilisée, ainsi que les défis techniques rencontrés au cours du développement.

\begin{figure}[h!]
\centering
\includegraphics[width=1.2\textwidth]{pageaccueil.png}
\caption{Page d'accueil de la plateforme (interface principale).}
\label{fig:pageaccueil}
\end{figure}

\section{Environnement de travail}

L'application a été développée en Python 3 avec le framework Flask pour le backend, et utilise HTML/CSS/JavaScript pour le frontend. Nous avons installé Ollama sur la machine pour accéder au modèle de langage (Mistral) localement via une API Python. Pour exécuter et tester les exercices de code, l'environnement inclut des compilateurs ou interpréteurs pour les langages supportés (Python, JavaScript, C, Java, Ruby), comme l'illustre le serveur configuré avec les commandes d'exécution correspondantes. L’interface a été testée sous différents navigateurs récents pour garantir la compatibilité, et le projet a été développé sous Windows, tout en étant également vérifié sous Linux afin d’assurer une compatibilité multiplateforme. 

\section{Description du projet et objectifs}

Ce projet consiste en une plateforme web qui permet à l'utilisateur de générer automatiquement des exercices de programmation corrigés. L'utilisateur choisit un thème (par exemple, un concept de programmation) et un langage (Python, Java, JavaScript, C, Ruby) via un formulaire dédié. En cliquant sur le bouton de génération, la plateforme envoie ces paramètres à l'IA pour créer un nouvel exercice. L'exercice généré comprend un énoncé détaillé, des consignes claires, ainsi qu'une solution commentée encadrée par un bloc de code, accompagnée de la sortie attendue. Par la suite, l'utilisateur peut modifier le code de l'exercice ou écrire sa propre solution et utiliser l'éditeur intégré pour l'exécuter et vérifier les résultats. Les principaux objectifs du projet sont de fournir un outil interactif d'apprentissage du code, d'automatiser la création de contenu pédagogique, et de se familiariser avec l'utilisation d'API d'IA moderne.

\section{Bibliothèques, Outils et technologies}

La plateforme repose sur plusieurs technologies : le backend utilise Flask en Python, ainsi que la bibliothèque Ollama pour interagir avec l'intelligence artificielle. Pour le frontend, nous utilisons HTML5, CSS3 et JavaScript pour créer une interface utilisateur réactive. Le traitement du texte Markdown est assuré par la bibliothèque Python \texttt{markdown} pour formater l'exercice et la réponse de l'IA en HTML affiché sur la page. Le code Python pour l'exécution d'exercices de différents langages repose sur les commandes systèmes (via \texttt{subprocess}) associées aux interpréteurs ou compilateurs installés. Enfin, l'API Flask et les requêtes AJAX en JavaScript assurent la communication entre le frontend et le serveur. Pour l’accompagenement de ce projet nous avons utilisé plusieurs modèle d’IA générative comme ChatGPT et Deepseek. Elle nous ont permis de créer une base et d’avoir plusieurs solution et plusieurs point de vu selon les problèmes rencontrés.

\section{Travail réalisé}




Pour ce projet, une grande partie a été réalisée lors des TD, donc en groupe. Au début, nous avions l’idée initiale et avons créé la base avec des IA génératives comme DeepSeek et ChatGPT. Cette base comprenait la page d’accueil (home) et la page de création d'exercices (index). À partir de cette interface basique, nous avons commencé par comprendre le fonctionnement de l’IA Ollama, car elle constitue le cœur de notre projet. Notre but était de commencer sur le home pour ensuite arriver à l’index pour choisir son exercice et enfin l’editor pour coder. Après avoir utilisés flask pour lier tout nos pages avec nos fichier, nous nous sommes concentrés sur Ollama.
Ensuite, nous avons atteint l’objectif le plus important du projet : pouvoir communiquer avec l’IA. Yahya et Karim se sont ensuite chargés de la liaison entre le client et l’IA, de la génération, à la réception de l’exercice, puis de l’envoi du code pour la correction. De son côté, Mehdi a réfléchi à la mise en place de plusieurs fonctionnalités utiles qui pourraient être ajoutées. Il était responsable de développer les idées qu’il pensait utile au projet.
Il a notamment ajouté un système de solution, permettant d’afficher la réponse lorsqu’on ne parvient pas à résoudre l’exercice. Ces solutions sont censées être détaillées pour aider à comprendre chaque étape.
Nous avions réussi a atteindre l’objectif principale de ce projet, générer un exercice et le corriger avec une IA. Cependant notre site nous permettait seulement d’écrire du code et de l’envoyer. Il nous a semblé important de pouvoir exécuter les codes pour comprendre ce qui ne fonctionne pas . Ainsi, Karim et Yahya ont ajouté une console d’exécution des programmes.
Nous avions désormais tout ce qui était important. Pour améliorer l’expérience utilisateur, Mehdi a proposé une nouvelle direction artistique, plus simple, afin de rendre l’apprentissage plus agréable.
Nous avions aussi pensé à ajouter un système de mémorisation des exercices pour éviter d’en proposer deux similaires à la suite. Cependant, cela était compleiqué à mettre en œuvre et peu intéréssant si l’utilisateur souhaite refaire des exercices pour s’entraîner.

\section{Difficultés rencontrées}
\begin{figure}[h!]
\centering
\includegraphics[width=1.2\textwidth]{formulaire.png}
\caption{Interface du formulaire de génération d'exercice.}
\label{fig:formulaire}
\end{figure}

Plusieurs difficultés ont été rencontrées lors du développement. L'une des principales était la manipulation du contenu Markdown renvoyé par l'IA : il a fallu nettoyer le texte pour extraire correctement la partie exercice et la solution encadrée par les balises \texttt{```} en utilisant des expressions régulières. Nous avons également dû gérer l'encodage Unicode (pour les accents ou caractères spéciaux) afin d'éviter des erreurs lors du traitement du texte. Parfois l'API Ollama mettait du temps à répondre ou retournait des erreurs de temps d'exécution, ce qui a nécessité l'implémentation de délais (timeouts) et la gestion d'exceptions pour informer l'utilisateur en cas de problème. Sur le plan frontend, intégrer les requêtes AJAX avec Flask a nécessité d'activer CORS et de formater correctement les données JSON échangées. Enfin, nous avons dû gérer l'exécution des différents langages de programmation en veillant à nettoyer les fichiers temporaires et à gérer les erreurs de compilation ou d'exécution renvoyées par l'interpréteur. Chaque obstacle a été surmonté par une recherche de solutions adaptées (ajustement des expressions régulières, gestion des erreurs \texttt{try/except} en Python, etc.), améliorant ainsi la robustesse de la plateforme.

\section{Bilan}



En conclusion, ce projet nous a permis de mettre en pratique plusieurs compétences techniques. L'utilisation de LaTeX pour rédiger ce rapport a été l'occasion d'apprendre la structuration de documents et l'inclusion d'éléments tels que des images et des figures. L'intégration de l'IA Ollama dans une application web nous a familiarisés avec les API de modèles de langage et la conception de prompts efficaces. Le développement du backend Flask et du frontend dynamique a renforcé nos connaissances en programmation web (gestion des requêtes, traitement des réponses JSON, mise en page HTML/CSS/JavaScript). Le projet a aussi permis de travailler sur la gestion des erreurs et le débogage de bout en bout : capturer et traiter les exceptions (dans les appels à l'IA, à l'exécution du code), et sécuriser les échanges de données.Il nous a également permis de nous améliorer en utilisant les nouveaux moyens de notre temps, les IA génératives. Elles sont énormément présentes et le seront encore plus alors. Les IA peuvent nous aider mais ne peuvent pas tout faire alors la compréhension est primordiale pour aboutir à quelque chose de concret biens les utiliser est quelque chose de primordial pour nous. Ce projet nous permet de comprendre comment elles fonctionnent, quels erreurs peuvent elles faire et comment apprendre avec elles et comment elles peuvent nous aider. Car comme il y a du bon et du mauvais nous ne pouvons pas tout prendre d’elle. Enfin, la génération dynamique de contenu pédagogique nous a appris à concevoir des algorithmes réactifs et à orchestrer plusieurs composants logiciels pour répondre à une demande utilisateur.


\section{Bibliographie}
\renewcommand{\bibname}{}
\renewcommand{\refname}{}
\begin{thebibliography}{2}
\bibitem[label]{cle} Auteur, TITRE, éditeur, année
\bibitem[LAM94]{lam1} L. LAMPORT, {\it \LaTeX: A Document Preparation System}, Addison-Wesley, 1994.
\end{thebibliography}

\newpage
\section{Webographie}
\begin{thebibliography}{2}
\bibitem[CAT]{cat} \url{savoircoder.fr/cat}
\bibitem[Flask]{flask} \url{https://flask.palletsprojects.com/}
\bibitem[Python]{python} \url{https://docs.python.org/}
\bibitem[Ollama]{ollama} \url{https://ollama.readthedocs.io/en/quickstart/}
\bibitem[HTML]{html} \url{https://developer.mozilla.org/fr/docs/Web/HTML}
\end{thebibliography}

\newpage
\section{Annexes}
\appendix
\makeatletter
\def\@seccntformat#1{Annexe~\csname the#1\endcsname:\quad}
\makeatother

	\section{Cahier des charges}
La plateforme doit permettre la génération d'exercices personnalisés en fonction du thème et du langage choisis, afficher l'énoncé et la solution du chatbot, et exécuter le code fourni. L'interface utilisateur simple doit être accessible via un navigateur web et communiquer avec un backend prenant en charge l'IA Ollama. Les exigences techniques incluaient l'utilisation de Flask pour le serveur, l'intégration d'Ollama pour la génération de texte, et la capacité d'exécuter du code dans plusieurs langages de programmation.

	\section{Exemple d'exécution du projet}
L'annexe présente un exemple concret d'exercice généré automatiquement par la plateforme, avec sa solution associée. 

\begin{figure}[h!]
\centering
\includegraphics[width=1.3\textwidth]{exercice.png}
\caption{Exemple d'exercice généré par l'IA, avec sa solution.}
\label{fig:exercice}
\end{figure}

	\section{Manuel utilisateur}
Après avoir lancé le serveur Flask avec \texttt{python app.py}, l'utilisateur accède à l'application via son navigateur à l'adresse locale : \texttt{http://localhost:5000}. Il sélectionne la notion et le langage dans le formulaire affiché (comme montré précédemment), puis clique sur ``Générer''. La plateforme affiche l'énoncé de l'exercice généré ainsi qu'un éditeur de code. L'utilisateur peut alors compléter l'exercice et recevoir une correction automatique par l'IA. L'utilisateur peut modifier le code ou en saisir un nouveau, puis cliquer sur ``Exécuter'' pour voir le résultat. Toute erreur d'exécution est affichée dans l'interface, ce qui facilite le débogage.

\end{document}
